plugins {
    id 'java'
}

sourceCompatibility = 1.8

repositories {
    jcenter()
}

dependencies {
    //needed for TA part
    compile 'org.seleniumhq.selenium:selenium-api:3.13.0'
    compile 'org.seleniumhq.selenium:selenium-java:3.141.0'
    compile 'org.seleniumhq.selenium:selenium-support:3.13.0'
    compile 'org.seleniumhq.selenium:selenium-chrome-driver:3.141.59'
    compile 'org.seleniumhq.selenium:selenium-firefox-driver:3.141.59'
    compile 'org.seleniumhq.selenium:selenium-htmlunit-driver:2.52.0'
    compile 'org.apache.commons:commons-lang3:3.9'

    //needed for unit tests in general
    testCompile 'junit:junit:4.12'
}

tasks.withType(JavaCompile) {
    options.encoding = 'UTF-8'
}


//--- CUSTOM GRADING SUPPORT ---//
import org.gradle.api.tasks.testing.logging.TestLogEvent

tasks.withType(Test) { testTask ->

    testLogging {
        events = [TestLogEvent.FAILED, TestLogEvent.PASSED, TestLogEvent.SKIPPED /*,TestLogEvent.STANDARD_OUT*/]
    }

    def (finalGrade, totalPoints) = [0, 0]

    // go through all test and retrieve the fake tasks (with grade info), then extract the results
    afterTest { descriptor, result ->
        if (result.resultType == TestResult.ResultType.SUCCESS) {
            def gradesMatcher = descriptor.name =~ ~/(\d+)\/(\d+)/
            if (gradesMatcher.find()) {
                def (grade, max) = [gradesMatcher.group(1), gradesMatcher.group(2)]
                finalGrade += grade.isInteger() ? grade as Integer : 0
                totalPoints += max.isInteger() ? max as Integer : 0
            }
        }
    }

    // present a nice interface with the results
    afterSuite { descriptor, result ->
        if (totalPoints > 0 && !descriptor.parent) { // will match the outermost suite
            def output = "|   FINAL GRADE: $finalGrade/$totalPoints | Result: ${result.resultType} (" +
                    "${result.successfulTestCount} tests passed" +
                    (result.failedTestCount > 0 ? ", ${result.failedTestCount} failed" : "") +
                    (result.skippedTestCount > 0 ? ", ${result.skippedTestCount} skipped" : "") + ")   |"
            def header = '-' * output.size()
            println("\n$header\n$output\n$header")
        }
    }
}
// force re-run of the test task each time
test.dependsOn(cleanTest)
